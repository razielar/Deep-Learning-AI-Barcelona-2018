{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Word Embedding\n",
    "## [IMDB dataset for binary sentiment classification](http://ai.stanford.edu/~amaas/data/sentiment/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "### Import modules:\n",
    "\n",
    "import tensorflow as tf \n",
    "print(tf.__version__)\n",
    "tf.enable_eager_execution() #For tf 1.x, for tf 2 you don't need this\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0901 17:50:58.236824 4596544960 dataset_builder.py:439] Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/Tensorflow/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0901 17:50:58.327132 4596544960 deprecation.py:323] From /anaconda3/envs/Tensorflow/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "imdb, info = tfds.load(\"imdb_reviews\", with_info= True, as_supervised= True)\n",
    "#tfds.list_builders() #to know all the datasets contained on tfds\n",
    "\n",
    "train_data, test_data = imdb['train'], imdb['test']\n",
    "\n",
    "### Create empty lists: \n",
    "training_sentences= []\n",
    "training_labels= []\n",
    "\n",
    "test_sentences= []\n",
    "test_labels= []\n",
    "\n",
    "for s,l in train_data: \n",
    "    training_sentences.append(str(s.numpy()))\n",
    "    training_labels.append(str(l.numpy()))\n",
    "\n",
    "for s,l in test_data:\n",
    "    test_sentences.append(str(s.numpy()))\n",
    "    test_labels.append(str(l.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig sentences: \n",
      " b'Sitting down to watch the 14th season of the Bachelor (\"On the Wings of Love\"), I knew I would be in for an \"interesting\" time. I had watched some of the previous seasons of the Bachelor in passing; watching an episode or two and missing the next three or so. I find that the Bachelor is often appealing and intriguing, though its quality and morality are often lacking.<br /><br />\"On the Wings of Love\" details the journey taken by Jake, a 31 year old commercial pilot from Dallas, Texas, to find true love, as true a love as one can find in a season-long reality-drama dating show. Jake meets 25 beautiful girls from all over the country. He begins to get to know them a bit, but it is mostly superficial; how well can you get to know someone in a few 5 minute conversations? Jake tries to make his true intentions known from the very beginning, at least to the audience. He noted that he doesn\\'t just want love or a good time, but he wants a fianc\\xc3\\xa9 or wife. We can only assume that he has made this clear to the women in the competition as well. If that is the case, it might explain, to a degree, some of the women\\'s actions. The women are super competitive. While they don\\'t even know Jake at all yet, they are still in it to win it no matter what the cost.<br /><br />Not only were the women competitive, but they were also confident and catty. Threats, backstabbing, and warnings of \"Watch out!\" all show that these women weren\\'t there for a good time either. Jake noted that he was not just looking for sex appeal, but looking for \"a connection.\" However, the girls pulled out all the stops to try to impress Jake with said sex appeal. They arrived at the mansion in skimpy dresses \\xc2\\x96 either low-cut or short.<br /><br />While some girls seemed to maintain their sense of decorum, others missed that memo altogether. One girl, Channy, noted that Jake was a \"good guy\" to whom she could be a \"naughty girl.\" She went on to say that Jake could land on her \"runway anytime.\" She got flack from the other girls for her provocative statement which showed their take on these situations.<br /><br />So, a reality dating show couldn\\'t be that bad, could it? Besides the obvious issue of sex-driven attraction, there are other issues that mar this seemingly harmless show. Is this the right way to find a future mate; vying for someone\\'s attention by flaunting oneself to extreme proportions? Unfortunately, however, that is what America has reduced dating to these days: pleasure and sex without commitment and a little happiness on the side.<br /><br />Another problem is the premature emotional attachment by which many of the girls bound themselves to Jake. A few girls in particular seemed to be overly attached. One girl said \"If I don\\'t get that first impression rose it will kill me!\" As mentioned before, they don\\'t even know him yet and she was talking about a specific rose, not just one of the 15 roses to keep from being eliminated.<br /><br />Michelle, in particular, seemed to have some issues with attachment to Jake. The other girls noticed it too. After one particular Michelle outburst, Vienna asserted that Michelle had a \"mental breakdown and we\\'ve only been here an hour.\" Michelle got the last rose of the evening on the first show \\xc2\\x96 narrowly missing elimination \\xc2\\x96 and was extremely emotional about it. The other girls thought it was simply ridiculous. Another girl also cried, but because she was eliminated.<br /><br />It began with Survivor, and from there it just took off \\xc2\\x96 reality TV. It shows our entertainment interests as a country; if we weren\\'t watching the shows and giving them good ratings, the networks would not continue to run them. The only logical conclusion that can be drawn is that enough of America is hooked. One thing is clear: America (in general) loves reality TV and its ensuing trappings.<br /><br />This begs me to question: why is it that we even like reality TV? What is it about it that draws us to it? Is it because we see the similarities to our own lives, or is it because we want to be sure that we are more stable and less pathetic than others? Whatever it is that draws us to it, we should be careful of the media and entertainment that we allow to fill our minds. I\\'m not saying that all reality TV shows are bad; however, I am saying that we need to evaluate each one.<br /><br />Episodes used for critique: Season Premier and Episode 2.' \n",
      "\n",
      "Training labels: '0' is negative \n",
      " 0 \n",
      "\n",
      "Test sentences: \n",
      " b\"I've watched the movie actually several times. And what i want to say about it is the only thing that made this movie high rank was the Burak Altay's incredible performance, absolutely nothing but that. Not even those silly model named Deniz Akkaya and some of these popular names at times in the movie... Burak is definitely very talented i've seen a few jobs he made and been through. Even though this is kind of horror movie, he's doing really good job in comedy movies and also in dramas too. I bet most of you all saw Asmali Konak the movie and TV series, those two would go for an example... All i'm gonna say is you better watch out for the new works coming out from Burak then you'll see.. Keep the good work bro, much love..\" \n",
      "\n",
      "Test labels: '1' is positive \n",
      " 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainig sentences: \\n\",training_sentences[0], \"\\n\")\n",
    "print(\"Training labels: '0' is negative \\n\",training_labels[0], \"\\n\")\n",
    "print(\"Test sentences: \\n\", test_sentences[0], \"\\n\")\n",
    "print(\"Test labels: '1' is positive \\n\", test_labels[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels: \n",
      " (25000,) \n",
      "\n",
      "Testing labels: \n",
      " (25000,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### When training my labels are expected to be numpy arrays: \n",
    "training_labels_final = np.array(training_labels)\n",
    "test_labels_final= np.array(test_labels)\n",
    "\n",
    "print(\"Training labels: \\n\", training_labels_final.shape, \"\\n\")\n",
    "print(\"Testing labels: \\n\", test_labels_final.shape, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize our sentences: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### -- Hyperparameters:\n",
    "vocab_size= 10000\n",
    "embedding_dim= 16\n",
    "max_length= 120\n",
    "trunc_type= 'post'\n",
    "oov_tok= \"<OOV>\"\n",
    "\n",
    "tokenizer= Tokenizer(num_words= vocab_size, oov_token= oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index= tokenizer.word_index\n",
    "sequences= tokenizer.texts_to_sequences(training_sentences)\n",
    "padded= pad_sequences(sequences=sequences, maxlen= max_length, truncating=trunc_type)\n",
    "\n",
    "### -- Test sequences: \n",
    "testing_sequences= tokenizer.texts_to_sequences(test_sentences)\n",
    "testing_padded= pad_sequences(testing_sequences, maxlen=max_length)\n",
    "\n",
    "### --- Neural Network: \n",
    "#1) DEFINE THE MODEL: Sequential: defines a SEQUENCE of layers in the NN\n",
    "# 1.1) Embedding layer: the key to text sentiment analysis in TF\n",
    "# 1.2) Flatten:\n",
    "# 1.3) Dense: fully connected neurons, first hidden layer of 6 neurons\n",
    "# 1.4) Dense: one neuron\n",
    "\n",
    "model= tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length= max_length), #the most important for NLP\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='softmax')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
